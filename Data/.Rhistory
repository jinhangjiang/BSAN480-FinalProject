Sys.getlocale()
assignment1 <- c(15,77,56,12,45,36,7,99,82,63)
mean(assignment1)
median(assignment1)
sd(assignment1)
install.packages(tidyverse)
install.packages("tidyverse")
install.packages("dplyr")
2^1.5
2^2
install.packages("pdftools")
install.packages(tm)
install.packages("tm")
install.packages("Rpoppler")
Sys.getenv()
Sys.getlocale()
Sys.setlocale("LC_ALL","English")
Sys.setlocale("LC_ALL","English")
Sys.setlocale("LC_MESSAGES", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_US.UTF-8")
Sys.setlocale("LC_MESSAGES", 'en_GB.UTF-8')
Sys.getlocale()
?Sys.setlocale
Sys.getlocale(category = "LC_ALL")
Sys.setlocale(category = "LC_ALL", locale = "")
Sys.setlocale(category = "LC_ALL", locale = "en")
install.koRpus.lang("en")
# load the package
library(koRpus.lang.en)
install.koRpus.lang("en")
library(koRpus.lang.en)
Sys.setlocale(category = "LC_ALL", locale = "en")
install.packages("tm")
install.packages("qdap")
install.packages("wordcloud")
install.packages("wordcloud2")
install.packages("RColorBrewer")
######## set up all the packages
library(tokenizers)
library(tm)
library(rJava)
library(openNLP)
library(coreNLP)
require("NLP")
## must run this one first
initCoreNLP(type = "english", parameterFile = NULL,
mem = "2g")
####### load data
options(java.parameters = "- Xmx1024m")
load("workspaces/CSR_documents_30samples.RData")
initCoreNLP(type = "english", parameterFile = NULL,
mem = "2g")
## must run this one first
#options(java.parameters = "- Xmx1024m")
library(XLConnect)
## must run this one first
#options(java.parameters = "- Xmx1024m")
install.packages("XLConnect")
library(XLConnect)
initCoreNLP(type = "english", parameterFile = NULL,
mem = "2g")
## must run this one first
#options(java.parameters = "- Xmx1024m")
#install.packages("XLConnect")
#library(XLConnect)
initCoreNLP(type = "english", parameterFile = NULL,
mem = "8g")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
## generate data
x1<- rnrom(200)
library(tidyverse)
## generate data
x1<- rnrom(200)
## generate data
x1<- rnorm(200)
x2<- rnorm(200)
??rnorm
y<-  -2+1.5*x1-0.8*x2+rnorm(200)
dat<- data.frame(y,x1,x2)
## random split to training and testing
index<- sample(nrow(dat),0.8*nrow(dat))
train<- dat[index,]
test<- dat[-index,]
#GoHawks#2020
install.packages("odbc")
install.packages("Sleuth2")
library(Sleuth2)
head(ex1029)
model = lm(wage~Education+Experience+Black+SMSA+Region, data = ex1029)
model = lm(Wage~Education+Experience+Black+SMSA+Region, data = ex1029)
summary(model)
install.packages("alr3")
library(alr3)
fuel2001 <- fuel2001
View(fuel2001)
m1 = lm(fuel2001$FuelC~., data = fuel2001)
summary(m1)
par(mfrow = c(2, 2))
plot(m1)
remove_spots <- which(row.names(fuel2001) %in% c("FL","TX","NY"))
no_tx_fl_ny <- fuel2001[-remove_spots,]
new_model <- lm(FuelC ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(new_model)
summary(m1)
attach(fuel2001)
m1 = lm(fuel2001$FuelC~Tax + Drivers + Income + log(Miles,10), data = fuel2001)
summary(m1)
par(mfrow = c(2, 2))
plot(m1)
hist(fuel2001$FuelC)
m2 <- lm(log(FuelC) ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(m2)
m2 <- lm(log(FuelC,10) ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(m2)
m2 <- lm(log(FuelC) ~ Tax + Drivers + Income + log(Miles,10), no_tx_fl_ny)
summary(m2)
exp(coefficients(m2))
plot(m2)
par(mfrow = c(2, 2))
plot(m2)
load("D:/1Github/CSRtm/workspaces/Specificity_Scores.RData")
house_data <- read.csv("http://www.lock5stat.com/datasets/HomesForSale.csv")
log_price <- log(house_data$Price, 10)
m1<- lm(log_price~Size+Beds, data = house_data)
summary(m1)
m2<- lm(log_price~Size+Beds+Baths, data = house_data)
summary(m2)
m3<- lm(log_price~Size+Beds+Baths+State, data = house_data)
summary(m1)
summary(m3)
anova(m1,m2)
anova(m2,m3)
AIC(m1,m2,m3)
help(state.x77)
state_data <- data.frame(state.x77)
state_data
pairs(state_data)
no_alaska <- state_data[-2,]
inter_model <- lm(Life.Exp ~1,no_alaska)
forward_model <- step(inter_model,direction = "forward",scope = (~Population+Income+Illiteracy+Murder+HS.Grad+Frost+Area))
final<-lm(Life.Exp ~ Murder + HS.Grad + Frost + Population, data = no_alaska)
summary(final)
setwd("D:/OneDrive - The University of Kansas/2020SPRING/BSAN480/BSAN480-FinalProject")
setwd("D:/OneDrive - The University of Kansas/2020SPRING/BSAN480/BSAN480-FinalProject/Data")
genres<- read.csv("embedding.csv")
genres
library(fpc)
## optimal k
wss<- NULL
for (i in 1:10){
fit1=kmeans(genres[,-1],centers = i)
wss=c(wss, fit1$tot.withinss)
}
plot(1:10, wss, type = "o")
a<-read.csv("tag.csv")
hist(a$RELEVANCE)
rm(a)
movie<-read.csv("movie")
movie<-read.csv("movie.csv")
hist(movie$REVENUE)
order(movie$REVENUE)
order(movie$REVENUE, decreasing = TRUE)
View(movie)
hist(log(movie$REVENUE))
exp(15)
exp(20)
exp(16)
exo(17)
exp(17)
exp(16.5)
exp(16.2)
exp(16.1)
hist(log(movie$REVENUE), main = "Log of Revenue")
hist(log(movie$REVENUE), main = "Revenue Distribution", xlab = "Log of Revenue")
hist(movie$STARTYEAR)
quantile(movie$ML_RATING)
genres<- read.csv("tr_embedding.csv")
genres
library(fpc)
## optimal k
wss<- NULL
for (i in 1:10){
fit1=kmeans(genres[,-1],centers = i)
wss=c(wss, fit1$tot.withinss)
}
plot(1:10, wss, type = "o")
plot(1:10, wss, type = "o", main = "WSS k=10")
fit=kmeans(genres[,-1],5)
plotcluster(genres[,-1], fit$cluster)
#subsample
subsample <- list()
for(i in 1:4){
subsample[[i]]<- genres[fit$cluster==i,]
}
subsample[[4]]
for(i in 1:5){
subsample[[i]]<- genres[fit$cluster==i,]
}
subsample[[1]]
subsample[[2]]
subsample[[3]]
subsample[[4]]
subsample[[5]]
a<- read.csv("tag")
a<- read.csv("tag.csv")
tag<- read.csv("tag.csv")
rm(a)
quantile(tag$RELEVANCE)
tag.top<-tag[tag$RELEVANCE>=0.13825]
tag.top<-tag[tag$RELEVANCE>=0.13825,]
head(tag.top,20)
tag_clean<- tag.top$TAG
tag_clean<- tag.top$TAG
tag_clean
library("NLP")
library("tm")
library("SnowballC")
library("RColorBrewer")
library("wordcloud2")
text<- tag.top$TAG
rm(tag_clean)
docs<-Corpus(VectorSource(text))
docs<-tm_map(docs, removeNumbers)
docs<-tm_map(docs, removeWords, stopwords("en"))
dtm<-TermDocumentMatrix(docs)
dtm
matrix<-as.matrix(dtm)
gc()
matrix<-as.matrix(dtm)
tag.top<-tag[tag$RELEVANCE>=0.2,]
text<- tag.top$TAG
docs<-Corpus(VectorSource(text))
docs<-tm_map(docs, removeNumbers)
docs<-tm_map(docs, removeWords, stopwords("en"))
dtm<-TermDocumentMatrix(docs)
matrix<-as.matrix(dtm)
quantile(tag$RELEVANCE)
?quantile
quantile(tag$RELEVANCE,type = 8)
quantile(tag$RELEVANCE, probs = seq(0,1,0.25))
quantile(tag$RELEVANCE, probs = seq(0,1,0.1))
tag.top<-tag[tag$RELEVANCE>=0.2905,]
text<- tag.top$TAG
dtm<-TermDocumentMatrix(docs)
matrix<-as.matrix(dtm)
quantile(tag$RELEVANCE, probs = seq(0,1,0.05))
tag.top<-tag[tag$RELEVANCE>=0.43625,]
text<- tag.top$TAG
dtm<-TermDocumentMatrix(docs)
matrix<-as.matrix(dtm)
gc()
library("NLP")
library("tm")
library("SnowballC")
library("RColorBrewer")
library("wordcloud2")
matrix<-as.matrix(dtm)
memory.limit()
quantile(tag$RELEVANCE, probs = seq(0,1,0.01))
tag.top<-tag[tag$RELEVANCE>=0.77725,]
text<- tag.top$TAG
dtm<-TermDocumentMatrix(docs)
matrix<-as.matrix(dtm)
